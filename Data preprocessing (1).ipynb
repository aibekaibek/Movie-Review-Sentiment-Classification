{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a38efe",
   "metadata": {},
   "source": [
    "## Цель предобработки данных\n",
    "\n",
    "Цель данного этапа — преобразовать текстовые отзывы в числовой формат,\n",
    "пригодный для обучения нейросетевой модели на основе LSTM.\n",
    "\n",
    "В ходе предобработки мы:\n",
    "- очищаем текст от шума\n",
    "- токенизируем отзывы\n",
    "- строим словарь\n",
    "- кодируем слова в индексы\n",
    "- выравниваем длины последовательностей\n",
    "- подготавливаем данные для PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "640b19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nurs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\nurs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341371ec",
   "metadata": {},
   "source": [
    "## Загрузка данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83de000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (50000, 2)\n",
      "Columns: ['review', 'sentiment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = Path(r\"C:\\\\Users\\\\nurs\\\\OneDrive\\\\Рабочий стол\\\\IMDB Dataset.csv\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12291566",
   "metadata": {},
   "source": [
    "Датасет содержит:\n",
    "- review — текст отзыва\n",
    "- sentiment — метка тональности (positive / negative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a0a2d",
   "metadata": {},
   "source": [
    "## Преобразование целевой переменной\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aca220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    25000\n",
      "0    25000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  label\n",
       "0  positive      1\n",
       "1  positive      1\n",
       "2  positive      1\n",
       "3  negative      0\n",
       "4  positive      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"] = df[\"sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
    "print(df[\"label\"].value_counts())\n",
    "df[[\"sentiment\", \"label\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb61464",
   "metadata": {},
   "source": [
    "Для обучения модели целевая переменная переводится в числовой формат:\n",
    "- 1 — положительный отзыв\n",
    "- 0 — отрицательный отзыв\n",
    "\n",
    "Датасет является полностью сбалансированным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0406cc4",
   "metadata": {},
   "source": [
    "## Базовая очистка текста\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb7ffdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. <br /><br />The...   \n",
       "\n",
       "                                        review_clean  \n",
       "0  one of the other reviewers has mentioned that ...  \n",
       "1  a wonderful little production the filming tech...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text_basic(text: str):\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "df[\"review_clean\"] = df[\"review\"].apply(clean_text_basic)\n",
    "df[[\"review\", \"review_clean\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b121ee",
   "metadata": {},
   "source": [
    "На данном шаге:\n",
    "- удаляются HTML-теги\n",
    "- текст приводится к нижнему регистру\n",
    "- нормализуются пробелы\n",
    "\n",
    "Агрессивная очистка (удаление стоп-слов, лемматизация) не применяется,\n",
    "так как она может ухудшить качество LSTM-моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791b025",
   "metadata": {},
   "source": [
    "## Токенизация текста\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2f30d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>[a, wonderful, little, production, the, filmin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_clean  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production the filming tech...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [one, of, the, other, reviewers, has, mentione...  \n",
       "1  [a, wonderful, little, production, the, filmin...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(text: str):\n",
    "    return word_tokenize(text)\n",
    "df[\"tokens\"] = df[\"review_clean\"].apply(tokenize_text)\n",
    "df[[\"review_clean\", \"tokens\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8cddc7",
   "metadata": {},
   "source": [
    "Токенизация выполняется с использованием библиотеки NLTK.\n",
    "Каждый отзыв преобразуется в список слов (токенов),\n",
    "что является оптимальным входом для LSTM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f236f26",
   "metadata": {},
   "source": [
    "## Построение словаря\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fcd2389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 20000\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 20_000\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "all_tokens = []\n",
    "for tokens in df[\"tokens\"]:\n",
    "    all_tokens.extend(tokens)\n",
    "token_freqs = Counter(all_tokens)\n",
    "most_common_tokens = token_freqs.most_common(VOCAB_SIZE - 2)\n",
    "word2idx = {\n",
    "    PAD_TOKEN: 0,\n",
    "    UNK_TOKEN: 1\n",
    "}\n",
    "\n",
    "for idx, (word, _) in enumerate(most_common_tokens, start=2):\n",
    "    word2idx[word] = idx\n",
    "print(\"Размер словаря:\", len(word2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeefbe8",
   "metadata": {},
   "source": [
    "Словарь строится на основе частоты слов:\n",
    "- используется 20 000 наиболее частых слов\n",
    "- <PAD> используется для padding\n",
    "- <UNK> используется для неизвестных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1b8d0",
   "metadata": {},
   "source": [
    "## Кодирование текста\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe25ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
       "      <td>[29, 5, 2, 78, 2062, 47, 1063, 12, 101, 150, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[a, wonderful, little, production, the, filmin...</td>\n",
       "      <td>[4, 395, 121, 355, 2, 1383, 2983, 7, 54, 17699...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [one, of, the, other, reviewers, has, mentione...   \n",
       "1  [a, wonderful, little, production, the, filmin...   \n",
       "\n",
       "                                             encoded  \n",
       "0  [29, 5, 2, 78, 2062, 47, 1063, 12, 101, 150, 4...  \n",
       "1  [4, 395, 121, 355, 2, 1383, 2983, 7, 54, 17699...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_tokens(tokens, word2idx):\n",
    "    return [\n",
    "        word2idx.get(token, word2idx[\"<UNK>\"])\n",
    "        for token in tokens\n",
    "    ]\n",
    "\n",
    "df[\"encoded\"] = df[\"tokens\"].apply(lambda x: encode_tokens(x, word2idx))\n",
    "df[[\"tokens\", \"encoded\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e714d",
   "metadata": {},
   "source": [
    "Каждое слово заменяется на соответствующий числовой индекс из словаря.\n",
    "Слова, отсутствующие в словаре, кодируются как <UNK>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc87ad9",
   "metadata": {},
   "source": [
    "## Padding и Truncation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1806596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "padded\n",
       "400    50000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 400\n",
    "PAD_IDX = word2idx[\"<PAD>\"]\n",
    "def pad_truncate(sequence, max_len, pad_idx):\n",
    "    if len(sequence) > max_len:\n",
    "        return sequence[:max_len]\n",
    "    else:\n",
    "        return sequence + [pad_idx] * (max_len - len(sequence))\n",
    "df[\"padded\"] = df[\"encoded\"].apply(\n",
    "    lambda x: pad_truncate(x, MAX_LEN, PAD_IDX)\n",
    ")\n",
    "df[\"padded\"].apply(len).value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95afce7d",
   "metadata": {},
   "source": [
    "Все последовательности приводятся к фиксированной длине 400:\n",
    "- длинные отзывы усекаются\n",
    "- короткие дополняются <PAD>\n",
    "\n",
    "Это необходимо для батчевого обучения нейросети.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c90be",
   "metadata": {},
   "source": [
    "## Разделение данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e11f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"padded\"].tolist()\n",
    "y = df[\"label\"].tolist()\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d60c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.50,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6547485c",
   "metadata": {},
   "source": [
    "Используется разбиение:\n",
    "- 70% — обучение\n",
    "- 15% — валидация\n",
    "- 15% — тест\n",
    "\n",
    "Баланс классов сохраняется с помощью stratify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4cb5943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 35000\n",
      "Val size: 7500\n",
      "Test size: 7500\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Val size:\", len(X_val))\n",
    "print(\"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5309db05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 7500, 7500)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.long)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float)\n",
    "        return x, y\n",
    "train_dataset = IMDBDataset(X_train, y_train)\n",
    "val_dataset   = IMDBDataset(X_val, y_val)\n",
    "test_dataset  = IMDBDataset(X_test, y_test)\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "563d73fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 400]), torch.Size([64]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "batch_X, batch_y = next(iter(train_loader))\n",
    "batch_X.shape, batch_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab80d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {idx: word for word, idx in word2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8ce41",
   "metadata": {},
   "source": [
    "## Сохранение данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8eacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = Path(\"artifacts\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "with open(SAVE_DIR / \"word2idx.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word2idx, f)\n",
    "with open(SAVE_DIR / \"idx2word.pkl\", \"wb\") as f:\n",
    "    pickle.dump(idx2word, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f6e75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"X_train\": torch.tensor(X_train, dtype=torch.long),\n",
    "        \"y_train\": torch.tensor(y_train, dtype=torch.float),\n",
    "        \"X_val\":   torch.tensor(X_val, dtype=torch.long),\n",
    "        \"y_val\":   torch.tensor(y_val, dtype=torch.float),\n",
    "        \"X_test\":  torch.tensor(X_test, dtype=torch.long),\n",
    "        \"y_test\":  torch.tensor(y_test, dtype=torch.float),\n",
    "    },\n",
    "    SAVE_DIR / \"dataset.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5e4c316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 0, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx), word2idx[\"<PAD>\"], word2idx[\"<UNK>\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
